
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Optimizing LLM Accuracy &#8212; Agentic Prototyping</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3_4_accuracy_optimization';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Advanced usage" href="3_5_reproducibility.html" />
    <link rel="prev" title="Reasoning Best Practices" href="3_3_reasoning_models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/ITRGLogoLightBlue.png" class="logo__image only-light" alt="Agentic Prototyping - Home"/>
    <script>document.write(`<img src="_static/ITRGLogoLightBlue.png" class="logo__image only-dark" alt="Agentic Prototyping - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Agentic Prototyping
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Core Concepts</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_0_dev_quick_start.html">Developer Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_1_model_selection.html">Model Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_2_prototype_to_production.html">Prototype to Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_3_structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_4_function_calling.html">Function calling</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2_0_agents_overview.html">Agents Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_1_agent_design_foundations.html">Agent Design Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_2_guardrails.html">Guardrails</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Best Practices</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="3_0_production.html">Production best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_1_safety.html">Safety Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_2_prompt_caching.html">Prompt caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_3_reasoning_models.html">Reasoning Best Practices</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Optimizing LLM Accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_5_reproducibility.html">Advanced usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_6_evaluation_design.html">Evals design best practices</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4_pharma_rd.html">Use Case: AI Co-Scientist for Pharma R&amp;D</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_insurance_claims.html">Use Case: Insurance Claim Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_financial_portfolio_analysis.html">Use Case: Financial Portfolio Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3_4_accuracy_optimization.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Optimizing LLM Accuracy</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-maximize-correctness-and-consistent-behavior-when-working-with-llms">How to maximize correctness and consistent behavior when working with LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-optimization-context">LLM optimization context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt engineering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-for-language-corrections">Prompt engineering for language corrections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive">Deep dive</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-long-context-to-scale-prompt-engineering">Using long context to scale prompt engineering</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-tools">Understanding the tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieval-augmented-generation-rag">Retrieval-augmented generation (RAG)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-of-the-above">All of the above</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-much-accuracy-is-good-enough-for-production">How much accuracy is “good enough” for production</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#business">Business</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#technical">Technical</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="optimizing-llm-accuracy">
<h1>Optimizing LLM Accuracy<a class="headerlink" href="#optimizing-llm-accuracy" title="Link to this heading">#</a></h1>
<p>Maximize correctness and consistent behavior when working with LLMs.</p>
<section id="how-to-maximize-correctness-and-consistent-behavior-when-working-with-llms">
<h2>How to maximize correctness and consistent behavior when working with LLMs<a class="headerlink" href="#how-to-maximize-correctness-and-consistent-behavior-when-working-with-llms" title="Link to this heading">#</a></h2>
<p>Optimizing LLMs is hard.</p>
<p>We’ve worked with many developers across both start-ups and enterprises, and the reason optimization is hard consistently boils down to these reasons:</p>
<ul class="simple">
<li><p>Knowing <strong>how to start</strong> optimizing accuracy</p></li>
<li><p><strong>When to use what</strong> optimization method</p></li>
<li><p>What level of accuracy is <strong>good enough</strong> for production</p></li>
</ul>
<p>This page gives a mental model for how to optimize LLMs for accuracy and behavior. We’ll explore methods like prompt engineering, retrieval-augmented generation (RAG) and fine-tuning. We’ll also highlight how and when to use each technique, and share a few pitfalls.</p>
<p>As you read through, it’s important to mentally relate these principles to what accuracy means for your specific use case. This may seem obvious, but there is a difference between producing a bad copy that a human needs to fix vs. refunding a customer <span class="math notranslate nohighlight">\(1000 rather than \)</span>100. You should enter any discussion on LLM accuracy with a rough picture of how much a failure by the LLM costs you, and how much a success saves or earns you - this will be revisited at the end, where we cover how much accuracy is “good enough” for production.</p>
</section>
<section id="llm-optimization-context">
<h2>LLM optimization context<a class="headerlink" href="#llm-optimization-context" title="Link to this heading">#</a></h2>
<p>Many “how-to” guides on optimization paint it as a simple linear flow - you start with prompt engineering, then you move on to retrieval-augmented generation, then fine-tuning. However, this is often not the case - these are all levers that solve different things, and to optimize in the right direction you need to pull the right lever.</p>
<p>It is useful to frame LLM optimization as more of a matrix:</p>
<p><img alt="Accuracy mental model diagram" src="_images/optimizing-accuracy.png" /></p>
<p>The typical LLM task will start in the bottom left corner with prompt engineering, where we test, learn, and evaluate to get a baseline. Once we’ve reviewed those baseline examples and assessed why they are incorrect, we can pull one of our levers:</p>
<ul class="simple">
<li><p><strong>Context optimization</strong>: You need to optimize for context when 1) the model lacks contextual knowledge because it wasn’t in its training set, 2) its knowledge is out of date, or 3) it requires knowledge of proprietary information. This axis maximizes response accuracy.</p></li>
<li><p><strong>LLM optimization</strong>: You need to optimize the LLM when 1) the model is producing inconsistent results with incorrect formatting, 2) the tone or style of speech is not correct, or 3) the reasoning is not being followed consistently. This axis maximizes consistency of behavior.</p></li>
</ul>
<p>In reality this turns into a series of optimization steps, where we evaluate, make a hypothesis on how to optimize, apply it, evaluate, and re-assess for the next step. Here’s an example of a fairly typical optimization flow:</p>
<p><img alt="Accuracy mental model journey diagram" src="_images/optimizing-accuracy-02.png" /></p>
<p>In this example, we do the following:</p>
<ol class="arabic simple">
<li><p>Begin with a prompt, then evaluate its performance</p></li>
<li><p>Add static few-shot examples, which should improve consistency of results</p></li>
<li><p>Add a retrieval step so the few-shot examples are brought in dynamically based on the question - this boosts performance by ensuring relevant context for each input</p></li>
<li><p>Prepare a dataset of 50+ examples and fine-tune a model to increase consistency</p></li>
<li><p>Tune the retrieval and add a fact-checking step to find hallucinations to achieve higher accuracy</p></li>
<li><p>Re-train the fine-tuned model on the new training examples which include our enhanced RAG inputs</p></li>
</ol>
<p>This is a fairly typical optimization pipeline for a tough business problem - it helps us decide whether we need more relevant context or if we need more consistent behavior from the model. Once we make that decision, we know which lever to pull as our first step toward optimization.</p>
<p>Now that we have a mental model, let’s dive into the methods for taking action on all of these areas. We’ll start in the bottom-left corner with Prompt Engineering.</p>
</section>
<section id="prompt-engineering">
<h2>Prompt engineering<a class="headerlink" href="#prompt-engineering" title="Link to this heading">#</a></h2>
<p>Prompt engineering is typically the best place to start**. It is often the only method needed for use cases like summarization, translation, and code generation where a zero-shot approach can reach production levels of accuracy and consistency.</p>
<p>This is because it forces you to define what accuracy means for your use case - you start at the most basic level by providing an input, so you need to be able to judge whether or not the output matches your expectations. If it is not what you want, then the reasons why will show you what to use to drive further optimizations.</p>
<p>To achieve this, you should always start with a simple prompt and an expected output in mind, and then optimize the prompt by adding context, instructions, or examples until it gives you what you want.</p>
<section id="optimization">
<h3>Optimization<a class="headerlink" href="#optimization" title="Link to this heading">#</a></h3>
<p>To optimize your prompts, I’ll mostly lean on strategies from the Prompt Engineering guide in the OpenAI API documentation. Each strategy helps you tune Context, the LLM, or both:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Strategy</p></th>
<th class="head"><p>Context optimization</p></th>
<th class="head"><p>LLM optimization</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Write clear instructions</p></td>
<td><p></p></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>Split complex tasks into simpler subtasks</p></td>
<td><p>X</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>Give GPTs time to “think”</p></td>
<td><p></p></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>Test changes systematically</p></td>
<td><p>X</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>Provide reference text</p></td>
<td><p>X</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Use external tools</p></td>
<td><p>X</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<p>These can be a little difficult to visualize, so we’ll run through an example where we test these out with a practical example. Let’s use gpt-4-turbo to correct Icelandic sentences to see how this can work.</p>
</section>
<section id="prompt-engineering-for-language-corrections">
<h3>Prompt engineering for language corrections<a class="headerlink" href="#prompt-engineering-for-language-corrections" title="Link to this heading">#</a></h3>
<p>We’ve seen that prompt engineering is a great place to start, and that with the right tuning methods we can push the performance pretty far.</p>
<p>However, the biggest issue with prompt engineering is that it often doesn’t scale - we either need dynamic context to be fed to allow the model to deal with a wider range of problems than we can deal with through adding content to the context, or we need more consistent behavior than we can achieve with few-shot examples.</p>
</section>
<section id="deep-dive">
<h3>Deep dive<a class="headerlink" href="#deep-dive" title="Link to this heading">#</a></h3>
<section id="using-long-context-to-scale-prompt-engineering">
<h4>Using long context to scale prompt engineering<a class="headerlink" href="#using-long-context-to-scale-prompt-engineering" title="Link to this heading">#</a></h4>
<blockquote>
<div><p>Long-context models allow prompt engineering to scale further - however, beware that models can struggle to maintain attention across very large prompts with complex instructions, and so you should always pair long context models with evaluation at different context sizes to ensure you don’t get lost in the middle. “Lost in the middle” is a term that addresses how an LLM can’t pay equal attention to all the tokens given to it at any one time. This can result in it missing information seemingly randomly. This doesn’t mean you shouldn’t use long context, but you need to pair it with thorough evaluation.</p>
</div></blockquote>
<p>One open-source contributor, Greg Kamradt, made a useful evaluation called Needle in A Haystack (NITA) which hid a piece of information at varying depths in long-context documents and evaluated the retrieval quality. This illustrates the problem with long-context - it promises a much simpler retrieval process where you can dump everything in context, but at a cost in accuracy.</p>
<p>So how far can you really take prompt engineering? The answer is that it depends, and the way you make your decision is through evaluations.</p>
</section>
</section>
<section id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">#</a></h3>
<p>This is why a good prompt with an evaluation set of questions and ground truth answers is the best output from this stage. If we have a set of 20+ questions and answers, and we have looked into the details of the failures and have a hypothesis of why they’re occurring, then we’ve got the right baseline to take on more advanced optimization methods.</p>
<p>Before you move on to more sophisticated optimization methods, it’s also worth considering how to automate this evaluation to speed up your iterations. Some common practices we’ve seen be effective here are:</p>
<ul class="simple">
<li><p>Using approaches like ROUGE or BERTScore to provide a finger-in-the-air judgment. This doesn’t correlate that closely with human reviewers, but can give a quick and effective measure of how much an iteration changed your model outputs.</p></li>
<li><p>Using GPT-4 as an evaluator as outlined in the G-Eval paper, where you provide the LLM a scorecard to assess the output as objectively as possible.</p></li>
</ul>
<p>If you want to dive deeper on these, check out this cookbook which takes you through all of them in practice.</p>
</section>
</section>
<section id="understanding-the-tools">
<h2>Understanding the tools<a class="headerlink" href="#understanding-the-tools" title="Link to this heading">#</a></h2>
<p>So you’ve done prompt engineering, you’ve got an eval set, and your model is still not doing what you need it to do. The most important next step is to diagnose where it is failing, and what tool works best to improve it.</p>
<p>Here is a basic framework for doing so:</p>
<p><img alt="Classifying memory problem diagram" src="_images/optimizing-accuracy-03.png" /></p>
<p>You can think of framing each failed evaluation question as an in-context or learned memory problem. As an analogy, imagine writing an exam. There are two ways you can ensure you get the right answer:</p>
<ul class="simple">
<li><p>You attend class for the last 6 months, where you see many repeated examples of how a particular concept works. This is learned memory - you solve this with LLMs by showing examples of the prompt and the response you expect, and the model learning from those.</p></li>
<li><p>You have the textbook with you, and can look up the right information to answer the question with. This is in-context memory - we solve this in LLMs by stuffing relevant information into the context window, either in a static way using prompt engineering, or in an industrial way using RAG.</p></li>
</ul>
<p>These two optimization methods are additive, not exclusive - they stack, and some use cases will require you to use them together to use optimal performance.</p>
<p>Let’s assume that we’re facing a short-term memory problem - for this we’ll use RAG to solve it.</p>
</section>
<section id="retrieval-augmented-generation-rag">
<h2>Retrieval-augmented generation (RAG)<a class="headerlink" href="#retrieval-augmented-generation-rag" title="Link to this heading">#</a></h2>
<p>RAG is the process of Retrieving content to Augment your LLM’s prompt before Generating an answer. It is used to give the model access to domain-specific context to solve a task.</p>
<p>RAG is an incredibly valuable tool for increasing the accuracy and consistency of an LLM - many of our largest customer deployments at OpenAI were done using only prompt engineering and RAG.</p>
<p><img alt="RAG diagram" src="_images/optimizing-accuracy-04.png" /></p>
<p>In this example we have embedded a knowledge base of statistics. When our user asks a question, we embed that question and retrieve the most relevant content from our knowledge base. This is presented to the model, which answers the question.</p>
<p>RAG applications introduce a new axis we need to optimize against, which is retrieval. For our RAG to work, we need to give the right context to the model, and then assess whether the model is answering correctly. I’ll frame these in a grid here to show a simple way to think about evaluation with RAG:</p>
<p><img alt="RAG evaluation diagram" src="_images/optimizing-accuracy-05.png" /></p>
<p>You have two areas your RAG application can break down:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Area</p></th>
<th class="head"><p>Problem</p></th>
<th class="head"><p>Resolution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Retrieval</p></td>
<td><p>You can supply the wrong context, so the model can’t possibly answer, or you can supply too much irrelevant context, which drowns out the real information and causes hallucinations.</p></td>
<td><p>Optimizing your retrieval, which can include:<br>- Tuning the search to return the right results.<br>- Tuning the search to include less noise.<br>- Providing more information in each retrieved result<br>These are just examples, as tuning RAG performance is an industry into itself, with libraries like LlamaIndex and LangChain giving many approaches to tuning here.</p></td>
</tr>
<tr class="row-odd"><td><p>LLM</p></td>
<td><p>The model can also get the right context and do the wrong thing with it.</p></td>
<td><p>Prompt engineering by improving the instructions and method the model uses, and, if showing it examples increases accuracy, adding in fine-tuning</p></td>
</tr>
</tbody>
</table>
</div>
<p>The key thing to take away here is that the principle remains the same from our mental model at the beginning - you evaluate to find out what has gone wrong, and take an optimization step to fix it. The only difference with RAG is you now have the retrieval axis to consider.</p>
<p>While useful, RAG only solves our in-context learning issues - for many use cases, the issue will be ensuring the LLM can learn a task so it can perform it consistently and reliably. For this problem we turn to fine-tuning.</p>
</section>
<section id="fine-tuning">
<h2>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Link to this heading">#</a></h2>
<p>To solve a learned memory problem, many developers will continue the training process of the LLM on a smaller, domain-specific dataset to optimize it for the specific task. This process is known as fine-tuning.</p>
<p>Fine-tuning is typically performed for one of two reasons:</p>
<ol class="arabic simple">
<li><p>To improve model accuracy on a specific task: Training the model on task-specific data to solve a learned memory problem by showing it many examples of that task being performed correctly.</p></li>
<li><p>To improve model efficiency: Achieve the same accuracy for less tokens or by using a smaller model.</p></li>
</ol>
<p>The fine-tuning process begins by preparing a dataset of training examples - this is the most critical step, as your fine-tuning examples must exactly represent what the model will see in the real world.</p>
<blockquote>
<div><p>Many customers use a process known as prompt baking, where you extensively log your prompt inputs and outputs during a pilot. These logs can be pruned into an effective training set with realistic examples.</p>
</div></blockquote>
<p><img alt="Fine-tuning process diagram" src="_images/optimizing-accuracy-06.png" /></p>
<p>Once you have this clean set, you can train a fine-tuned model by performing a training run - depending on the platform or framework you’re using for training you may have hyperparameters you can tune here, similar to any other machine learning model. We always recommend maintaining a hold-out set to use for evaluation following training to detect overfitting. For tips on how to construct a good training set you can check out the guidance in our Fine-tuning documentation. Once training is completed, the new, fine-tuned model is available for inference.</p>
<p>For optimizing fine-tuning we’ll focus on best practices we observe with OpenAI’s model customization offerings, but these principles should hold true with other providers and OSS offerings. The key practices to observe here are:</p>
<ul class="simple">
<li><p>Start with prompt-engineering: Have a solid evaluation set from prompt engineering which you can use as a baseline. This allows a low-investment approach until you’re confident in your base prompt.</p></li>
<li><p>Start small, focus on quality: Quality of training data is more important than quantity when fine-tuning on top of a foundation model. Start with 50+ examples, evaluate, and then dial your training set size up if you haven’t yet hit your accuracy needs, and if the issues causing incorrect answers are due to consistency/behavior and not context.</p></li>
<li><p>Ensure your examples are representative: One of the most common pitfalls we see is non-representative training data, where the examples used for fine-tuning differ subtly in formatting or form from what the LLM sees in production. For example, if you have a RAG application, fine-tune the model with RAG examples in it so it isn’t learning how to use the context zero-shot.</p></li>
</ul>
</section>
<section id="all-of-the-above">
<h2>All of the above<a class="headerlink" href="#all-of-the-above" title="Link to this heading">#</a></h2>
<p>These techniques stack on top of each other - if your early evals show issues with both context and behavior, then it’s likely you may end up with fine-tuning + RAG in your production solution. This is ok - these stack to balance the weaknesses of both approaches. Some of the main benefits are:</p>
<ul class="simple">
<li><p>Using fine-tuning to minimize the tokens used for prompt engineering, as you replace instructions and few-shot examples with many training examples to ingrain consistent behaviour in the model.</p></li>
<li><p>Teaching complex behavior using extensive fine-tuning</p></li>
<li><p>Using RAG to inject context, more recent content or any other specialized context required for your use cases</p></li>
</ul>
<p>Using these tools to improve language translation</p>
<p>Now you should have an appreciation for RAG and fine-tuning, and when each is appropriate. The last thing you should appreciate with these tools is that once you introduce them there is a trade-off here in our speed to iterate:</p>
<ul class="simple">
<li><p>For RAG you need to tune the retrieval as well as LLM behavior</p></li>
<li><p>With fine-tuning you need to rerun the fine-tuning process and manage your training and validation sets when you do additional tuning.</p></li>
</ul>
<p>Both of these can be time-consuming and complex processes, which can introduce regression issues as your LLM application becomes more complex. If you take away one thing from this paper, let it be to squeeze as much accuracy out of basic methods as you can before reaching for more complex RAG or fine-tuning - let your accuracy target be the objective, not jumping for RAG + FT because they are perceived as the most sophisticated.</p>
</section>
<section id="how-much-accuracy-is-good-enough-for-production">
<h2>How much accuracy is “good enough” for production<a class="headerlink" href="#how-much-accuracy-is-good-enough-for-production" title="Link to this heading">#</a></h2>
<p>Tuning for accuracy can be a never-ending battle with LLMs - they are unlikely to get to 99.999% accuracy using off-the-shelf methods. This section is all about deciding when is enough for accuracy - how do you get comfortable putting an LLM in production, and how do you manage the risk of the solution you put out there.</p>
<p>I find it helpful to think of this in both a business and technical context. I’m going to describe the high level approaches to managing both, and use a customer service help-desk use case to illustrate how we manage our risk in both cases.</p>
<section id="business">
<h3>Business<a class="headerlink" href="#business" title="Link to this heading">#</a></h3>
<p>For the business it can be hard to trust LLMs after the comparative certainties of rules-based or traditional machine learning systems, or indeed humans! A system where failures are open-ended and unpredictable is a difficult circle to square.</p>
<p>An approach I’ve seen be successful here was for a customer service use case - for this, we did the following:</p>
<p>First we identify the primary success and failure cases, and assign an estimated cost to them. This gives us a clear articulation of what the solution is likely to save or cost based on pilot performance.</p>
<ul class="simple">
<li><p>For example, a case getting solved by an AI where it was previously solved by a human may save $20.</p></li>
<li><p>Someone getting escalated to a human when they shouldn’t might cost $40</p></li>
<li><p>In the worst case scenario, a customer gets so frustrated with the AI they churn, costing us $1000. We assume this happens in 5% of cases.</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Event</p></th>
<th class="head"><p>Value</p></th>
<th class="head"><p>Number of cases</p></th>
<th class="head"><p>Total value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AI success</p></td>
<td><p>+20</p></td>
<td><p>815</p></td>
<td><p>$16,300</p></td>
</tr>
<tr class="row-odd"><td><p>AI failure (escalation)</p></td>
<td><p>-40</p></td>
<td><p>175.75</p></td>
<td><p>$7,030</p></td>
</tr>
<tr class="row-even"><td><p>AI failure (churn)</p></td>
<td><p>-1000</p></td>
<td><p>9.25</p></td>
<td><p>$9,250</p></td>
</tr>
<tr class="row-odd"><td><p>Result</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p>+20</p></td>
</tr>
<tr class="row-even"><td><p>Break-even accuracy</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p>81.5%</p></td>
</tr>
</tbody>
</table>
</div>
<p>The other thing we did is to measure the empirical stats around the process which will help us measure the macro impact of the solution. Again using customer service, these could be:</p>
<ul class="simple">
<li><p>The CSAT score for purely human interactions vs. AI ones</p></li>
<li><p>The decision accuracy for retrospectively reviewed cases for human vs. AI</p></li>
<li><p>The time to resolution for human vs. AI</p></li>
</ul>
<p>In the customer service example, this helped us make two key decisions following a few pilots to get clear data:</p>
<ol class="arabic simple">
<li><p>Even if our LLM solution escalated to humans more than we wanted, it still made an enormous operational cost saving over the existing solution. This meant that an accuracy of even 85% could be ok, if those 15% were primarily early escalations.</p></li>
<li><p>Where the cost of failure was very high, such as a fraud case being incorrectly resolved, we decided the human would drive and the AI would function as an assistant. In this case, the decision accuracy stat helped us make the call that we weren’t comfortable with full autonomy.</p></li>
</ol>
</section>
<section id="technical">
<h3>Technical<a class="headerlink" href="#technical" title="Link to this heading">#</a></h3>
<p>On the technical side it is more clear - now that the business is clear on the value they expect and the cost of what can go wrong, your role is to build a solution that handles failures gracefully in a way that doesn’t disrupt the user experience.</p>
<p>Let’s use the customer service example one more time to illustrate this, and we’ll assume we’ve got a model that is 85% accurate in determining intent. As a technical team, here are a few ways we can minimize the impact of the incorrect 15%:</p>
<ul class="simple">
<li><p>We can prompt engineer the model to prompt the customer for more information if it isn’t confident, so our first-time accuracy may drop but we may be more accurate given 2 shots to determine intent.</p></li>
<li><p>We can give the second-line assistant the option to pass back to the intent determination stage, again giving the UX a way of self-healing at the cost of some additional user latency.</p></li>
<li><p>We can prompt engineer the model to hand off to a human if the intent is unclear, which costs us some operational savings in the short-term but may offset customer churn risk in the long term.</p></li>
</ul>
<p>Those decisions then feed into our UX, which gets slower at the cost of higher accuracy, or more human interventions, which feed into the cost model covered in the business section above.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="3_3_reasoning_models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Reasoning Best Practices</p>
      </div>
    </a>
    <a class="right-next"
       href="3_5_reproducibility.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Advanced usage</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-maximize-correctness-and-consistent-behavior-when-working-with-llms">How to maximize correctness and consistent behavior when working with LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-optimization-context">LLM optimization context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt engineering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-for-language-corrections">Prompt engineering for language corrections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-dive">Deep dive</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-long-context-to-scale-prompt-engineering">Using long context to scale prompt engineering</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-tools">Understanding the tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieval-augmented-generation-rag">Retrieval-augmented generation (RAG)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine-tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-of-the-above">All of the above</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-much-accuracy-is-good-enough-for-production">How much accuracy is “good enough” for production</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#business">Business</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#technical">Technical</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>