
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Evaluating model performance &#8212; Agentic Prototyping</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1_14_evals';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Moderation" href="1_15_moderation.html" />
    <link rel="prev" title="Retrieval" href="1_13_retrieval.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/ITRGLogoLightBlue.png" class="logo__image only-light" alt="Agentic Prototyping - Home"/>
    <script>document.write(`<img src="_static/ITRGLogoLightBlue.png" class="logo__image only-dark" alt="Agentic Prototyping - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    üóìÔ∏è Agentic AI Workshop Schedule Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Core Concepts</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_0_dev_quick_start.html">Developer Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_1_prompt_engineering.html">Prompt Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_2_model_selection.html">Model Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_3_prototype_to_production.html">Prototype to Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_4_structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_5_function_calling.html">Function calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_6_conversational_state.html">Conversation state</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_7_streaming.html">Streaming API responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_8_file_inputs.html">File inputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_9_image_generation.html">Image generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_10_text_to_speech.html">Text to speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_11_speech_to_text.html">Speech to text</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_12_embeddings.html">Vector embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_13_retrieval.html">Retrieval</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Evaluating model performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_15_moderation.html">Moderation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2_0_agents_overview.html">Agents Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_1_agent_design_foundations.html">Agent Design Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_2_openai_agents.html">OpenAI Agents SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_3_quick_start.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_4_building_agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_5_running_agents.html">Running agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_6_tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_7_mcp.html">Model context protocol (MCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_8_handoffs.html">Handoffs</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_9_observability.html">Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_10_context_management.html">Context management</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_11_guardrails.html">Guardrails</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_12_orchestration.html">Orchestrating multiple agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_13_models.html">Models</a></li>

<li class="toctree-l1"><a class="reference internal" href="2_14_visualization.html">Agent Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_15_agent_output.html">Agent Output (Results)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Best Practices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="3_0_production.html">Production best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_1_safety.html">Safety Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_2_prompt_caching.html">Prompt caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_3_reasoning_models.html">Reasoning Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_4_accuracy_optimization.html">Optimizing LLM Accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_5_reproducibility.html">Advanced usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_6_evaluation_design.html">Evals design best practices</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4_pharma_rd.html">Use Case: AI Co-Scientist for Pharma R&amp;D</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_insurance_claims.html">Use Case: Insurance Claim Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_financial_portfolio_analysis.html">Use Case: Financial Portfolio Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/1_14_evals.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Evaluating model performance</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-and-improve-model-outputs-through-evaluations">Test and improve model outputs through evaluations.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-an-eval-for-a-task">Create an eval for a task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-a-prompt-with-your-eval">Test a prompt with your eval</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#uploading-test-data">Uploading test data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-an-eval-run">Creating an eval run</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-the-results">Analyze the results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#video-evals-in-the-dashboard">Video: evals in the dashboard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluating-model-performance">
<h1>Evaluating model performance<a class="headerlink" href="#evaluating-model-performance" title="Link to this heading">#</a></h1>
<section id="test-and-improve-model-outputs-through-evaluations">
<h2>Test and improve model outputs through evaluations.<a class="headerlink" href="#test-and-improve-model-outputs-through-evaluations" title="Link to this heading">#</a></h2>
<p>Evaluations (often called <strong>evals</strong>) test model outputs to ensure they meet style and content criteria that you specify. Writing evals to understand how your LLM applications are performing against your expectations, especially when upgrading or trying new models, is an essential component to building reliable applications.</p>
<p>In this guide, we will focus on <strong>configuring evals programmatically using the <a class="reference external" href="https://platform.openai.com/docs/api-reference/evals">Evals API</a></strong>. If you prefer, you can also configure evals <a class="reference external" href="https://platform.openai.com/evaluations">in the OpenAI dashboard</a>.</p>
<p>Broadly, there are three steps to build and run evals for your LLM application.</p>
<ol class="arabic simple">
<li><p>Describe the task to be done as an eval</p></li>
<li><p>Run your eval with test inputs (a prompt and input data)</p></li>
<li><p>Analyze the results, then iterate and improve on your prompt</p></li>
</ol>
<p>This process is somewhat similar to behavior-driven development (BDD), where you begin by specifying how the system should behave before implementing and testing the system. Let‚Äôs see how we would complete each of the steps above using the <a class="reference external" href="https://platform.openai.com/docs/api-reference/evals">Evals API</a>.</p>
</section>
<section id="create-an-eval-for-a-task">
<h2>Create an eval for a task<a class="headerlink" href="#create-an-eval-for-a-task" title="Link to this heading">#</a></h2>
<p>Creating an eval begins by describing a task to be done by a model. Let‚Äôs say that we would like to use a model to classify the contents of IT support tickets into one of three categories: <code class="docutils literal notranslate"><span class="pre">Hardware</span></code>, <code class="docutils literal notranslate"><span class="pre">Software</span></code>, or <code class="docutils literal notranslate"><span class="pre">Other</span></code>.</p>
<p>To implement this use case with the <a class="reference external" href="https://platform.openai.com/docs/api-reference/chat">Chat Completions API</a>, you might write code like this that combines a <a class="reference internal" href="#/docs/guides/text"><span class="xref myst">developer message</span></a> with a user message containing the text of a support ticket.</p>
<p><strong>Categorize IT support tickets</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">instructions</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are an expert in categorizing IT support tickets. Given the support </span>
<span class="s2">ticket below, categorize the request into one of &quot;Hardware&quot;, &quot;Software&quot;, </span>
<span class="s2">or &quot;Other&quot;. Respond with only one of those words.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">ticket</span> <span class="o">=</span> <span class="s2">&quot;My monitor won&#39;t turn on - help!&quot;</span>

<span class="n">completion</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;developer&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">instructions</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ticket</span><span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
<p>Let‚Äôs set up an eval to test this behavior <a class="reference internal" href="#/docs/api-reference/evals"><span class="xref myst">via API</span></a>. An eval needs two key ingredients:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data_source_config</span></code>: A schema for the test data you will use along with the eval.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">testing_criteria</span></code>: The <a class="reference internal" href="#/docs/guides/graders"><span class="xref myst">graders</span></a> that determine if the model output is correct.</p></li>
</ul>
<p>Create an eval</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">eval_obj</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">evals</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;IT Ticket Categorization&quot;</span><span class="p">,</span>
    <span class="n">data_source_config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;custom&quot;</span><span class="p">,</span>
        <span class="s2">&quot;item_schema&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;ticket_text&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">},</span>
                <span class="s2">&quot;correct_label&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">},</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;ticket_text&quot;</span><span class="p">,</span> <span class="s2">&quot;correct_label&quot;</span><span class="p">],</span>
        <span class="p">},</span>
        <span class="s2">&quot;include_sample_schema&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">testing_criteria</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string_check&quot;</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Match output to human label&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;{{ sample.output_text }}&quot;</span><span class="p">,</span>
            <span class="s2">&quot;operation&quot;</span><span class="p">:</span> <span class="s2">&quot;eq&quot;</span><span class="p">,</span>
            <span class="s2">&quot;reference&quot;</span><span class="p">:</span> <span class="s2">&quot;{{ item.correct_label }}&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">eval_obj</span><span class="p">)</span>
</pre></div>
</div>
<p>Explanation: data_source_config parameter</p>
<p>Running this eval will require a test data set that represents the type of data you expect your prompt to work with (more on creating the test data set later in this guide). In our <code class="docutils literal notranslate"><span class="pre">data_source_config</span></code> parameter, we specify that each <strong>item</strong> in the data set will conform to a <a class="reference external" href="https://json-schema.org/">JSON schema</a> with two properties:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ticket_text</span></code>: a string of text with the contents of a support ticket</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">correct_label</span></code>: a ‚Äúground truth‚Äù output that the model should match, provided by a human</p></li>
</ul>
<p>Since we will be referencing a <strong>sample</strong> in our test criteria (the output generated by a model given our prompt), we also set <code class="docutils literal notranslate"><span class="pre">include_sample_schema</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;custom&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;item_schema&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;object&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;properties&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;ticket&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string&quot;</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="nt">&quot;category&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string&quot;</span><span class="w"> </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;required&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;ticket&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;category&quot;</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;include_sample_schema&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Explanation: testing_criteria parameter</p>
<p>In our <code class="docutils literal notranslate"><span class="pre">testing_criteria</span></code>, we define how we will conclude if the model output satisfies our requirements for each item in the data set. In this case, we just want the model to output one of three category strings based on the input ticket. The string it outputs should exactly match the human-labeled <code class="docutils literal notranslate"><span class="pre">correct_label</span></code> field in our test data. So in this case, we will want to use a <code class="docutils literal notranslate"><span class="pre">string_check</span></code> grader to evaluate the output.</p>
<p>In the test configuration, we will introduce template syntax, represented by the <code class="docutils literal notranslate"><span class="pre">{{</span></code> and <code class="docutils literal notranslate"><span class="pre">}}</span></code> brackets below. This is how we will insert dynamic content into the test for this eval.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">{{</span> <span class="pre">item.correct_label</span> <span class="pre">}}</span></code> refers to the ground truth value in our test data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">{{</span> <span class="pre">sample.output_text</span> <span class="pre">}}</span></code> refers to the content we will generate from a model to evaluate our prompt - we‚Äôll show how to do that when we actually kick off the eval run.</p></li>
</ul>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string_check&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Category string match&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;input&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{ sample.output_text }}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;operation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eq&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;reference&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{ item.category }}&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>After creating the eval, it will be assigned a UUID that you will need to address it later when kicking off a run.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval_67e321d23b54819096e6bfe140161184&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;data_source_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;custom&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;schema&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="err">...</span><span class="w"> </span><span class="err">omi</span><span class="kc">tte</span><span class="err">d</span><span class="w"> </span><span class="kc">f</span><span class="err">or</span><span class="w"> </span><span class="err">brevi</span><span class="kc">t</span><span class="err">y...</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;testing_criteria&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Match output to human label&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Match output to human label-c4fdf789-2fa5-407f-8a41-a6f4f9afd482&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string_check&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;input&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{ sample.output_text }}&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;reference&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{ item.correct_label }}&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;operation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eq&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;IT Ticket Categorization&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1742938578</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now that we‚Äôve created an eval that describes the desired behavior of our application, let‚Äôs test a prompt with a set of test data.</p>
</section>
<section id="test-a-prompt-with-your-eval">
<h2>Test a prompt with your eval<a class="headerlink" href="#test-a-prompt-with-your-eval" title="Link to this heading">#</a></h2>
<p>Now that we have defined how we want our app to behave in an eval, let‚Äôs construct a prompt that reliably generates the correct output for a representative sample of test data.</p>
<section id="uploading-test-data">
<h3>Uploading test data<a class="headerlink" href="#uploading-test-data" title="Link to this heading">#</a></h3>
<p>There are several ways to provide test data for eval runs, but it may be convenient to upload a <a class="reference external" href="https://jsonlines.org/">JSONL</a> file that contains data in the schema we specified when we created our eval. A sample JSONL file that conforms to the schema we set up is below:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;item&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;ticket_text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;My monitor won&#39;t turn on!&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;correct_label&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Hardware&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span>
<span class="p">{</span><span class="w"> </span><span class="nt">&quot;item&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;ticket_text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;I&#39;m in vim and I can&#39;t quit!&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;correct_label&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Software&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span>
<span class="p">{</span><span class="w"> </span><span class="nt">&quot;item&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;ticket_text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Best restaurants in Cleveland?&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;correct_label&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Other&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
<p>This data set contains both test inputs and ground truth labels to compare model outputs against.</p>
<p>Next, let‚Äôs upload our test data file to the OpenAI platform so we can reference it later. You can upload files <a class="reference internal" href="#/storage/files"><span class="xref myst">in the dashboard here</span></a>, but it‚Äôs possible to <a class="reference internal" href="#/docs/api-reference/files/create"><span class="xref myst">upload files via API</span></a> as well. The samples below assume you are running the command in a directory where you saved the sample JSON data above to a file called <code class="docutils literal notranslate"><span class="pre">tickets.jsonl</span></code>:</p>
<p>Upload a test data file</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">file</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">file</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tickets.jsonl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">),</span>
    <span class="n">purpose</span><span class="o">=</span><span class="s2">&quot;evals&quot;</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</pre></div>
</div>
<p>When you upload the file, make note of the unique <code class="docutils literal notranslate"><span class="pre">id</span></code> property in the response payload (also available in the UI if you uploaded via the browser) - we will need to reference that value later:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file-CwHg45Fo7YXwkWRPUkLNHW&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;purpose&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;evals&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;filename&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tickets.jsonl&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;bytes&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">208</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;created_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1742834798</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;expires_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;processed&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;status_details&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="creating-an-eval-run">
<h3>Creating an eval run<a class="headerlink" href="#creating-an-eval-run" title="Link to this heading">#</a></h3>
<p>With our test data in place, let‚Äôs evaluate a prompt and see how it performs against our test criteria. Via API, we can do this by <a class="reference internal" href="#/docs/api-reference/evals/createRun"><span class="xref myst">creating an eval run</span></a>.</p>
<p>Make sure to replace <code class="docutils literal notranslate"><span class="pre">YOUR_EVAL_ID</span></code> and <code class="docutils literal notranslate"><span class="pre">YOUR_FILE_ID</span></code> with the unique IDs of the eval configuration and test data files you created in the steps above.</p>
<p>Create an eval run</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">evals</span><span class="o">.</span><span class="n">runs</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="s2">&quot;YOUR_EVAL_ID&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Categorization text run&quot;</span><span class="p">,</span>
    <span class="n">data_source</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;completions&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
        <span class="s2">&quot;input_messages&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;template&quot;</span><span class="p">,</span>
            <span class="s2">&quot;template&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;developer&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are an expert in categorizing IT support tickets. Given the support ticket below, categorize the request into one of &#39;Hardware&#39;, &#39;Software&#39;, or &#39;Other&#39;. Respond with only one of those words.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;{{ item.ticket_text }}&quot;</span><span class="p">},</span>
            <span class="p">],</span>
        <span class="p">},</span>
        <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;file_id&quot;</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;YOUR_FILE_ID&quot;</span><span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">run</span><span class="p">)</span>
</pre></div>
</div>
<p>When we create the run, we set up a <a class="reference internal" href="#/docs/guides/text?api-mode=chat"><span class="xref myst">Chat Completions</span></a> messages array with the prompt we would like to test. This prompt is used to generate a model response for every line of test data in your data set. We can use the double curly brace syntax to template in the dynamic variable <code class="docutils literal notranslate"><span class="pre">item.ticket_text</span></code>, which is drawn from the current test data item.</p>
<p>If the eval run is successfully created, you‚Äôll receive an API response that looks like this:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval.run&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;evalrun_67e44c73eb6481909f79a457749222c7&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;eval_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval_67e44c5becec81909704be0318146157&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;report_url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://platform.openai.com/evaluations/abc123&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;queued&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Categorization text run&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;created_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1743015028</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;result_counts&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="err">...</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;per_model_usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;per_testing_criteria_results&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;data_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completions&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file_id&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file-J7MoX9ToHXp2TutMEeYnwj&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;input_messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;template&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;template&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="p">{</span>
<span class="w">                    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;message&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;developer&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_text&quot;</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;You are an expert in....&quot;</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span>
<span class="w">                    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;message&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_text&quot;</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{item.ticket_text}}&quot;</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;sampling_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;error&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Your eval run has now been queued, and it will execute asynchronously as it processes every row in your data set. With our configuration, it will generate completions for testing with the prompt and model we specified.</p>
</section>
</section>
<section id="analyze-the-results">
<h2>Analyze the results<a class="headerlink" href="#analyze-the-results" title="Link to this heading">#</a></h2>
<p>Depending on the size of your dataset, the eval run may take some time to complete. You can view current status in the dashboard, but you can also <a class="reference external" href="https://platform.openai.com/docs/api-reference/evals/getRun">fetch the current status of an eval run via API</a>:</p>
<p>Retrieve eval run status</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">evals</span><span class="o">.</span><span class="n">runs</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="s2">&quot;YOUR_EVAL_ID&quot;</span><span class="p">,</span> <span class="s2">&quot;YOUR_RUN_ID&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">run</span><span class="p">)</span>
</pre></div>
</div>
<p>You‚Äôll need the UUID of both your eval and eval run to fetch its status. When you do, you‚Äôll see eval run data that looks like this:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval.run&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;evalrun_67e44c73eb6481909f79a457749222c7&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;eval_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;eval_67e44c5becec81909704be0318146157&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;report_url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://platform.openai.com/evaluations/xxx&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Categorization text run&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1743015028</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;result_counts&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;total&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;errored&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;failed&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;passed&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;per_model_usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4o-2024-08-06&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;invocation_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">166</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">172</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;cached_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;per_testing_criteria_results&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;testing_criteria&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Match output to human label-40d67441-5000-4754-ab8c-181c125803ce&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;passed&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;failed&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;data_source&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completions&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file_id&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;file-J7MoX9ToHXp2TutMEeYnwj&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;input_messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;template&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;template&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">          </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;message&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;developer&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_text&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;You are an expert in categorizing IT support tickets. Given the support ticket below, categorize the request into one of Hardware, Software, or Other. Respond with only one of those words.&quot;</span>
<span class="w">          </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">          </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;message&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;input_text&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;{{item.ticket_text}}&quot;</span>
<span class="w">          </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4.1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;sampling_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;error&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;metadata&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The API response contains granular information about test criteria results, API usage for generating model responses, and a <code class="docutils literal notranslate"><span class="pre">report_url</span></code> property that takes you to a page in the dashboard where you can explore the results visually.</p>
<p>In our simple test, the model reliably generated the content we wanted for a small test case sample. In reality, you will often have to run your eval with more criteria, different prompts, and different data sets. But the process above gives you all the tools you need to build robust evals for your LLM apps!</p>
</section>
<section id="video-evals-in-the-dashboard">
<h2>Video: evals in the dashboard<a class="headerlink" href="#video-evals-in-the-dashboard" title="Link to this heading">#</a></h2>
<p>The Evaluations tooling <a class="reference external" href="https://platform.openai.com/evaluations">in the OpenAI dashboard</a> evolves quickly and may not match exactly the UI shown below, but this video will give you a quick overview of how to set up and run evals using the browser-based UI.</p>
<video controls width="100%">
  <source src="../images/evals.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
</section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h2>
<p>Now you know how to create and run evals via API, and using the dashboard! Here are a few other resources that may be useful to you as you continue to improve your model results.</p>
<p><a class="reference external" href="https://cookbook.openai.com/examples/evaluation/use-cases/regression">Cookbook: Detecting prompt regressions. Keep tabs on the performance of your prompts as you iterate on them. </a>[</p>
<p><a class="reference external" href="https://cookbook.openai.com/examples/evaluation/use-cases/bulk-experimentation">Cookbook: Bulk model and prompt experimentation. Compare the results of many different prompts and models at once.</a>[</p>
<p><a class="reference external" href="https://cookbook.openai.com/examples/evaluation/use-cases/completion-monitoring">Cookbook: Monitoring stored completions Examine stored completions to test for prompt regressions.</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1_13_retrieval.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Retrieval</p>
      </div>
    </a>
    <a class="right-next"
       href="1_15_moderation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Moderation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-and-improve-model-outputs-through-evaluations">Test and improve model outputs through evaluations.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-an-eval-for-a-task">Create an eval for a task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-a-prompt-with-your-eval">Test a prompt with your eval</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#uploading-test-data">Uploading test data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-an-eval-run">Creating an eval run</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-the-results">Analyze the results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#video-evals-in-the-dashboard">Video: evals in the dashboard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>