{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developer Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI API provides a simple interface to state-of-the-art AI models for text generation, natural language processing, computer vision, and more. This example generates text output from a prompt, as you might using ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize Openai Client library and Setup API keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the client with API key from environment\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under a starry sky, a gentle unicorn tiptoed through the moonlit forest, leaving a trail of sparkling dreams for every sleeping creature.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Image Inputs\n",
    "\n",
    "You can provide image inputs to the model as well. Scan receipts, analyze screenshots, or find objects in the real world with computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows two canines:\n",
      "\n",
      "- On the **left** is a **wolf** (Canis lupus), which is a wild animal closely related to domestic dogs.\n",
      "- On the **right** is a **pug**, which is a breed of domestic dog known for its wrinkled face and short muzzle.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": \"What two dogs are in this image?\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Comparison_of_a_wolf_and_a_pug.png/1920px-Comparison_of_a_wolf_and_a_pug.png\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend the model with tools\n",
    "\n",
    "Give the model access to new data and capabilities using tools. You can either call your own custom code, or use one of OpenAI's powerful built-in tools. This example uses web search to give the model access to the latest information on the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of June 23, 2025, one notable positive news story is the successful reintroduction of helmeted honeyeaters to Cardinia in Victoria, Australia. These critically endangered birds have returned to the area for the first time since the Ash Wednesday bushfires in 1983, marking a significant milestone in conservation efforts. ([globalgoodnews.com](https://globalgoodnews.com/?utm_source=openai))\n",
      "\n",
      "Additionally, a 14-year-old from Dallas, Siddharth Nandyala, has developed an AI-powered app capable of detecting heart disease in just seven seconds using only a smartphone's microphone. This innovation has the potential to revolutionize early detection and treatment of heart conditions. ([globalgoodnews.com](https://globalgoodnews.com/?utm_source=openai))\n",
      "\n",
      "Furthermore, the Yurok Tribe in the United States is celebrating the return of ancestral homelands, following historic dam removals. This restoration supports the tribe's cultural and environmental initiatives. ([goodnewsnetwork.org](https://www.goodnewsnetwork.org/?utm_source=openai))\n",
      "\n",
      "These stories highlight significant advancements in environmental conservation, technological innovation, and cultural restoration. \n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=\"What was a positive news story from today?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliver blazing fast AI experiences\n",
    "\n",
    "Using either the new Realtime API or server-sent streaming events, you can build high performance, low-latency experiences for your users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_6859932093a88199882c392e696fd8990504aced7eea8f67', created_at=1750700832.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_6859932093a88199882c392e696fd8990504aced7eea8f67', created_at=1750700832.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=None), sequence_number=3, type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='Double', item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, sequence_number=4, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bubble', item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, sequence_number=5, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bath', item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, sequence_number=6, type='response.output_text.delta')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, sequence_number=7, type='response.output_text.delta')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, sequence_number=8, text='Double bubble bath!', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', output_index=0, part=ResponseOutputText(annotations=[], text='Double bubble bath!', type='output_text', logprobs=None), sequence_number=9, type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', content=[ResponseOutputText(annotations=[], text='Double bubble bath!', type='output_text', logprobs=None)], role='assistant', status='completed', type='message'), output_index=0, sequence_number=10, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_6859932093a88199882c392e696fd8990504aced7eea8f67', created_at=1750700832.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68599321137c8199994383a8becbe84d0504aced7eea8f67', content=[ResponseOutputText(annotations=[], text='Double bubble bath!', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=13, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=5, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=18), user=None, store=True), sequence_number=11, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'double bubble bath'.\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build agents\n",
    "\n",
    "Use the OpenAI platform to build agents capable of taking action—like controlling computers—on behalf of your users. Use the Agents SDK for Python or TypeScript to create orchestration logic on the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, estoy bien, gracias. ¿Y tú, cómo estás?\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    ")\n",
    "\n",
    "# Define your async function\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
    "    return result.final_output\n",
    "\n",
    "# In Jupyter, use await directly\n",
    "result = await main()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
