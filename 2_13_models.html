
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Models &#8212; Agentic Prototyping</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2_13_models';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reasoning Best Practices" href="3_3_reasoning_models.html" />
    <link rel="prev" title="Context management" href="2_10_context_management.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/ITRGLogoLightBlue.png" class="logo__image only-light" alt="Agentic Prototyping - Home"/>
    <script>document.write(`<img src="_static/ITRGLogoLightBlue.png" class="logo__image only-dark" alt="Agentic Prototyping - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    üóìÔ∏è Agentic AI Workshop Schedule Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Day 1 ‚Äî Foundations (LLMs, Prompts, Agent Mindset)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="0_0_agent_prd.html">üìã Agent Product Requirements Document (PRD)</a></li>



<li class="toctree-l1"><a class="reference internal" href="1_0_dev_quick_start.html">Developer Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_1_prompt_engineering.html">Prompt Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_2_model_selection.html">Model Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_0_agents_overview.html">Agents Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_1_agent_design_foundations.html">Agent Design Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_6_conversational_state.html">Conversation state</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Day 2 ‚Äî SDK, Agent Building, Tools &amp; RAG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2_2_openai_agents.html">OpenAI Agents SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_3_quick_start.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_4_building_agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_5_running_agents.html">Running agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_6_tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_5_function_calling.html">Function calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_12_embeddings.html">Vector embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_13_retrieval.html">Retrieval</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Day 3 ‚Äî Production Readiness (Safety, Guardrails, Observability)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2_9_observability.html">Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_15_moderation.html">Moderation</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_1_safety.html">Safety Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_11_guardrails.html">Guardrails</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_2_prompt_caching.html">Prompt caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_0_production.html">Production best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_12_orchestration.html">Orchestrating multiple agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_7_mcp.html">Model context protocol (MCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_8_handoffs.html">Handoffs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Day 4 ‚Äî Evaluation, Optimization, UI &amp; Visualization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_14_evals.html">Evaluating model performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_6_evaluation_design.html">Evals design best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_4_accuracy_optimization.html">Optimizing LLM Accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_14_visualization.html">Agent Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_15_agent_output.html">Agent Output (Results)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Day 5 ‚Äî Demo, Polish, and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_3_prototype_to_production.html">Prototype to Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_5_reproducibility.html">Advanced usage</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference &amp; Advanced Topics (Optional)</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_4_structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_7_streaming.html">Streaming API responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_8_file_inputs.html">File inputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_9_image_generation.html">Image generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_10_text_to_speech.html">Text to speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_11_speech_to_text.html">Speech to text</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_10_context_management.html">Context management</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Models</a></li>

<li class="toctree-l1"><a class="reference internal" href="3_3_reasoning_models.html">Reasoning Best Practices</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4_pharma_rd.html">Use Case: AI Co-Scientist for Pharma R&amp;D</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_insurance_claims.html">Use Case: Insurance Claim Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_financial_portfolio_analysis.html">Use Case: Financial Portfolio Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2_13_models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-openai-models">Non-OpenAI models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-ways-to-use-non-openai-models">Other ways to use non-OpenAI models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixing-and-matching-models">Mixing and matching models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-issues-with-using-other-llm-providers">Common issues with using other LLM providers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tracing-client-error-401">Tracing client error 401</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#responses-api-support">Responses API support</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structured-outputs-support">Structured outputs support</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixing-models-across-providers">Mixing models across providers</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-any-model-via-litellm">Using any model via LiteLLM</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="models">
<h1>Models<a class="headerlink" href="#models" title="Link to this heading">#</a></h1>
<p>The Agents SDK comes with out-of-the-box support for OpenAI models in two flavors:</p>
<ul class="simple">
<li><p><strong>Recommended</strong>: the [<code class="docutils literal notranslate"><span class="pre">OpenAIResponsesModel</span></code>][agents.models.openai_responses.OpenAIResponsesModel], which calls OpenAI APIs using the new <a class="reference external" href="https://platform.openai.com/docs/api-reference/responses">Responses API</a>.</p></li>
<li><p>The [<code class="docutils literal notranslate"><span class="pre">OpenAIChatCompletionsModel</span></code>][agents.models.openai_chatcompletions.OpenAIChatCompletionsModel], which calls OpenAI APIs using the <a class="reference external" href="https://platform.openai.com/docs/api-reference/chat">Chat Completions API</a>.</p></li>
</ul>
<section id="non-openai-models">
<h2>Non-OpenAI models<a class="headerlink" href="#non-openai-models" title="Link to this heading">#</a></h2>
<p>You can use most other non-OpenAI models via the <a class="reference internal" href="#./litellm.md"><span class="xref myst">LiteLLM integration</span></a>. First, install the litellm dependency group:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;openai-agents[litellm]&quot;</span>
</pre></div>
</div>
<p>Then, use any of the <a class="reference external" href="https://docs.litellm.ai/docs/providers">supported models</a> with the <code class="docutils literal notranslate"><span class="pre">litellm/</span></code> prefix:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">claude_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;litellm/anthropic/claude-3-5-sonnet-20240620&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="n">gemini_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;litellm/gemini/gemini-2.5-flash-preview-04-17&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<section id="other-ways-to-use-non-openai-models">
<h3>Other ways to use non-OpenAI models<a class="headerlink" href="#other-ways-to-use-non-openai-models" title="Link to this heading">#</a></h3>
<p>You can integrate other LLM providers in 3 more ways (examples <a class="reference external" href="https://github.com/openai/openai-agents-python/tree/main/examples/model_providers/">here</a>):</p>
<ol class="arabic simple">
<li><p>[<code class="docutils literal notranslate"><span class="pre">set_default_openai_client</span></code>][agents.set_default_openai_client] is useful in cases where you want to globally use an instance of <code class="docutils literal notranslate"><span class="pre">AsyncOpenAI</span></code> as the LLM client. This is for cases where the LLM provider has an OpenAI compatible API endpoint, and you can set the <code class="docutils literal notranslate"><span class="pre">base_url</span></code> and <code class="docutils literal notranslate"><span class="pre">api_key</span></code>. See a configurable example in <a class="reference external" href="https://github.com/openai/openai-agents-python/tree/main/examples/model_providers/custom_example_global.py">examples/model_providers/custom_example_global.py</a>.</p></li>
<li><p>[<code class="docutils literal notranslate"><span class="pre">ModelProvider</span></code>][agents.models.interface.ModelProvider] is at the <code class="docutils literal notranslate"><span class="pre">Runner.run</span></code> level. This lets you say ‚Äúuse a custom model provider for all agents in this run‚Äù. See a configurable example in <a class="reference external" href="https://github.com/openai/openai-agents-python/tree/main/examples/model_providers/custom_example_provider.py">examples/model_providers/custom_example_provider.py</a>.</p></li>
<li><p>[<code class="docutils literal notranslate"><span class="pre">Agent.model</span></code>][agents.agent.Agent.model] lets you specify the model on a specific Agent instance. This enables you to mix and match different providers for different agents. See a configurable example in <a class="reference external" href="https://github.com/openai/openai-agents-python/tree/main/examples/model_providers/custom_example_agent.py">examples/model_providers/custom_example_agent.py</a>. An easy way to use most available models is via the <a class="reference internal" href="#./litellm.md"><span class="xref myst">LiteLLM integration</span></a>.</p></li>
</ol>
<p>In cases where you do not have an API key from <code class="docutils literal notranslate"><span class="pre">platform.openai.com</span></code>, we recommend disabling tracing via <code class="docutils literal notranslate"><span class="pre">set_tracing_disabled()</span></code>, or setting up a <a class="reference internal" href="#../tracing.md"><span class="xref myst">different tracing processor</span></a>.</p>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>In these examples, we use the Chat Completions API/model, because most LLM providers don&#39;t yet support the Responses API. If your LLM provider does support it, we recommend using Responses.
</pre></div>
</div>
</section>
</section>
<section id="mixing-and-matching-models">
<h2>Mixing and matching models<a class="headerlink" href="#mixing-and-matching-models" title="Link to this heading">#</a></h2>
<p>Within a single workflow, you may want to use different models for each agent. For example, you could use a smaller, faster model for triage, while using a larger, more capable model for complex tasks. When configuring an [<code class="docutils literal notranslate"><span class="pre">Agent</span></code>][agents.Agent], you can select a specific model by either:</p>
<ol class="arabic simple">
<li><p>Passing the name of a model.</p></li>
<li><p>Passing any model name + a [<code class="docutils literal notranslate"><span class="pre">ModelProvider</span></code>][agents.models.interface.ModelProvider] that can map that name to a Model instance.</p></li>
<li><p>Directly providing a [<code class="docutils literal notranslate"><span class="pre">Model</span></code>][agents.models.interface.Model] implementation.</p></li>
</ol>
<p>!!!note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>While our SDK supports both the [`OpenAIResponsesModel`][agents.models.openai_responses.OpenAIResponsesModel] and the [`OpenAIChatCompletionsModel`][agents.models.openai_chatcompletions.OpenAIChatCompletionsModel] shapes, we recommend using a single model shape for each workflow because the two shapes support a different set of features and tools. If your workflow requires mixing and matching model shapes, make sure that all the features you&#39;re using are available on both.
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">AsyncOpenAI</span><span class="p">,</span> <span class="n">OpenAIChatCompletionsModel</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>

<span class="n">spanish_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Spanish agent&quot;</span><span class="p">,</span>
    <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;You only speak Spanish.&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;o3-mini&quot;</span><span class="p">,</span> <span class="c1"># (1)!</span>
<span class="p">)</span>

<span class="n">english_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;English agent&quot;</span><span class="p">,</span>
    <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;You only speak English&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">OpenAIChatCompletionsModel</span><span class="p">(</span> <span class="c1"># (2)!</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
        <span class="n">openai_client</span><span class="o">=</span><span class="n">AsyncOpenAI</span><span class="p">()</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">triage_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Triage agent&quot;</span><span class="p">,</span>
    <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;Handoff to the appropriate agent based on the language of the request.&quot;</span><span class="p">,</span>
    <span class="n">handoffs</span><span class="o">=</span><span class="p">[</span><span class="n">spanish_agent</span><span class="p">,</span> <span class="n">english_agent</span><span class="p">],</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">Runner</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">triage_agent</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hola, ¬øc√≥mo est√°s?&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">final_output</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Sets the name of an OpenAI model directly.</p></li>
<li><p>Provides a [<code class="docutils literal notranslate"><span class="pre">Model</span></code>][agents.models.interface.Model] implementation.</p></li>
</ol>
<p>When you want to further configure the model used for an agent, you can pass [<code class="docutils literal notranslate"><span class="pre">ModelSettings</span></code>][agents.models.interface.ModelSettings], which provides optional model configuration parameters such as temperature.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">ModelSettings</span>

<span class="n">english_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;English agent&quot;</span><span class="p">,</span>
    <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;You only speak English&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
    <span class="n">model_settings</span><span class="o">=</span><span class="n">ModelSettings</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="common-issues-with-using-other-llm-providers">
<h2>Common issues with using other LLM providers<a class="headerlink" href="#common-issues-with-using-other-llm-providers" title="Link to this heading">#</a></h2>
<section id="tracing-client-error-401">
<h3>Tracing client error 401<a class="headerlink" href="#tracing-client-error-401" title="Link to this heading">#</a></h3>
<p>If you get errors related to tracing, this is because traces are uploaded to OpenAI servers, and you don‚Äôt have an OpenAI API key. You have three options to resolve this:</p>
<ol class="arabic simple">
<li><p>Disable tracing entirely: [<code class="docutils literal notranslate"><span class="pre">set_tracing_disabled(True)</span></code>][agents.set_tracing_disabled].</p></li>
<li><p>Set an OpenAI key for tracing: [<code class="docutils literal notranslate"><span class="pre">set_tracing_export_api_key(...)</span></code>][agents.set_tracing_export_api_key]. This API key will only be used for uploading traces, and must be from <a class="reference external" href="https://platform.openai.com/">platform.openai.com</a>.</p></li>
<li><p>Use a non-OpenAI trace processor. See the <a class="reference internal" href="#../tracing.md#custom-tracing-processors"><span class="xref myst">tracing docs</span></a>.</p></li>
</ol>
</section>
<section id="responses-api-support">
<h3>Responses API support<a class="headerlink" href="#responses-api-support" title="Link to this heading">#</a></h3>
<p>The SDK uses the Responses API by default, but most other LLM providers don‚Äôt yet support it. You may see 404s or similar issues as a result. To resolve, you have two options:</p>
<ol class="arabic simple">
<li><p>Call [<code class="docutils literal notranslate"><span class="pre">set_default_openai_api(&quot;chat_completions&quot;)</span></code>][agents.set_default_openai_api]. This works if you are setting <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> and <code class="docutils literal notranslate"><span class="pre">OPENAI_BASE_URL</span></code> via environment vars.</p></li>
<li><p>Use [<code class="docutils literal notranslate"><span class="pre">OpenAIChatCompletionsModel</span></code>][agents.models.openai_chatcompletions.OpenAIChatCompletionsModel]. There are examples <a class="reference external" href="https://github.com/openai/openai-agents-python/tree/main/examples/model_providers/">here</a>.</p></li>
</ol>
</section>
<section id="structured-outputs-support">
<h3>Structured outputs support<a class="headerlink" href="#structured-outputs-support" title="Link to this heading">#</a></h3>
<p>Some model providers don‚Äôt have support for <a class="reference external" href="https://platform.openai.com/docs/guides/structured-outputs">structured outputs</a>. This sometimes results in an error that looks something like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">BadRequestError</span><span class="p">:</span> <span class="n">Error</span> <span class="n">code</span><span class="p">:</span> <span class="mi">400</span> <span class="o">-</span> <span class="p">{</span><span class="s1">&#39;error&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;message&#39;</span><span class="p">:</span> <span class="s2">&quot;&#39;response_format.type&#39; : value is not one of the allowed values [&#39;text&#39;,&#39;json_object&#39;]&quot;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;invalid_request_error&#39;</span><span class="p">}}</span>

</pre></div>
</div>
<p>This is a shortcoming of some model providers - they support JSON outputs, but don‚Äôt allow you to specify the <code class="docutils literal notranslate"><span class="pre">json_schema</span></code> to use for the output. We are working on a fix for this, but we suggest relying on providers that do have support for JSON schema output, because otherwise your app will often break because of malformed JSON.</p>
</section>
</section>
<section id="mixing-models-across-providers">
<h2>Mixing models across providers<a class="headerlink" href="#mixing-models-across-providers" title="Link to this heading">#</a></h2>
<p>You need to be aware of feature differences between model providers, or you may run into errors. For example, OpenAI supports structured outputs, multimodal input, and hosted file search and web search, but many other providers don‚Äôt support these features. Be aware of these limitations:</p>
<ul class="simple">
<li><p>Don‚Äôt send unsupported <code class="docutils literal notranslate"><span class="pre">tools</span></code> to providers that don‚Äôt understand them</p></li>
<li><p>Filter out multimodal inputs before calling models that are text-only</p></li>
<li><p>Be aware that providers that don‚Äôt support structured JSON outputs will occasionally produce invalid JSON.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="using-any-model-via-litellm">
<h1>Using any model via LiteLLM<a class="headerlink" href="#using-any-model-via-litellm" title="Link to this heading">#</a></h1>
<p>!!! note</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>The LiteLLM integration is in beta. You may run into issues with some model providers, especially smaller ones. Please report any issues via [Github issues](https://github.com/openai/openai-agents-python/issues) and we&#39;ll fix quickly.
</pre></div>
</div>
<p><a class="reference external" href="https://docs.litellm.ai/docs/">LiteLLM</a> is a library that allows you to use 100+ models via a single interface. We‚Äôve added a LiteLLM integration to allow you to use any AI model in the Agents SDK.</p>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>You‚Äôll need to ensure <code class="docutils literal notranslate"><span class="pre">litellm</span></code> is available. You can do this by installing the optional <code class="docutils literal notranslate"><span class="pre">litellm</span></code> dependency group:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;openai-agents[litellm]&quot;</span>
</pre></div>
</div>
<p>Once done, you can use [<code class="docutils literal notranslate"><span class="pre">LitellmModel</span></code>][agents.extensions.models.litellm_model.LitellmModel] in any agent.</p>
</section>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h2>
<p>This is a fully working example. When you run it, you‚Äôll be prompted for a model name and API key. For example, you could enter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">openai/gpt-4.1</span></code> for the model, and your OpenAI API key</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anthropic/claude-3-5-sonnet-20240620</span></code> for the model, and your Anthropic API key</p></li>
<li><p>etc</p></li>
</ul>
<p>For a full list of models supported in LiteLLM, see the <a class="reference external" href="https://docs.litellm.ai/docs/providers">litellm providers docs</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">function_tool</span><span class="p">,</span> <span class="n">set_tracing_disabled</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agents.extensions.models.litellm_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LitellmModel</span>

<span class="nd">@function_tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_weather</span><span class="p">(</span><span class="n">city</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[debug] getting weather for </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;The weather in </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2"> is sunny.&quot;</span>


<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Assistant&quot;</span><span class="p">,</span>
        <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;You only respond in haikus.&quot;</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">LitellmModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">),</span>
        <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">Runner</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="s2">&quot;What&#39;s the weather in Tokyo?&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">final_output</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># First try to get model/api key from args</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>

    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--model&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--api-key&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Enter a model name for Litellm: &quot;</span><span class="p">)</span>

    <span class="n">api_key</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">api_key</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">api_key</span><span class="p">:</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Enter an API key for Litellm: &quot;</span><span class="p">)</span>

    <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">api_key</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="2_10_context_management.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Context management</p>
      </div>
    </a>
    <a class="right-next"
       href="3_3_reasoning_models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Reasoning Best Practices</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-openai-models">Non-OpenAI models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-ways-to-use-non-openai-models">Other ways to use non-OpenAI models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixing-and-matching-models">Mixing and matching models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-issues-with-using-other-llm-providers">Common issues with using other LLM providers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tracing-client-error-401">Tracing client error 401</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#responses-api-support">Responses API support</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structured-outputs-support">Structured outputs support</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixing-models-across-providers">Mixing models across providers</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-any-model-via-litellm">Using any model via LiteLLM</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>